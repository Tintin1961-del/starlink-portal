from fastapi import FastAPI, Request
from pydantic import BaseModel
import httpx
import openai
import os

app = FastAPI()

STARLINK_API_BASE = "https://api.enterprise.starlink.com/v1"
STARLINK_API_KEY = os.getenv("STARLINK_API_KEY")
CHARGEBEE_API_KEY = os.getenv("CHARGEBEE_API_KEY")
CHARGEBEE_SITE = os.getenv("CHARGEBEE_SITE")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

class UserQuery(BaseModel):
    user_id: str
    message: str

async def get_starlink_status(user_id: str):
    async with httpx.AsyncClient() as client:
        resp = await client.get(
            f"{STARLINK_API_BASE}/terminals/{user_id}/status",
            headers={"Authorization": f"Bearer {STARLINK_API_KEY}"}
        )
        return resp.json()

async def get_starlink_usage(user_id: str):
    async with httpx.AsyncClient() as client:
        resp = await client.get(
            f"{STARLINK_API_BASE}/terminals/{user_id}/usage",
            headers={"Authorization": f"Bearer {STARLINK_API_KEY}"}
        )
        return resp.json()

async def get_chargebee_subscription(user_id: str):
    async with httpx.AsyncClient() as client:
        resp = await client.get(
            f"https://{CHARGEBEE_SITE}.chargebee.com/api/v2/customers/{user_id}/subscriptions",
            auth=(CHARGEBEE_API_KEY, "")
        )
        return resp.json()

async def ask_gpt(message: str, context: dict = {}):
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a helpful support assistant for Starlink and billing."},
            {"role": "user", "content": message},
            *context.get("messages", [])
        ]
    )
    return response.choices[0].message["content"]

@app.post("/support")
async def support_bot(query: UserQuery):
    user_id = query.user_id
    message = query.message.lower()

    if "usage" in message or "how much data" in message:
        usage = await get_starlink_usage(user_id)
        reply = f"You've used {usage.get('data_used_gb', '?')} GB so far this billing period."

    elif "offline" in message or "status" in message:
        status = await get_starlink_status(user_id)
        reply = f"Your terminal is currently {status.get('connection_state', 'unknown')}. Last pinfastapi
httpx
openai
uvicorng was {status.get('last_contact_time', 'N/A')}"

    elif "invoice" in message or "billing" in message:
        subs = await get_chargebee_subscription(user_id)
        plan = subs['list'][0]['subscription']['plan_id'] if subs['list'] else 'Unknown'
        reply = f"You're currently subscribed to plan: {plan}."

    else:services:# Starlink Support Bot

This is a FastAPI backend for a support bot that integrates:
- Starlink Enterprise API (live terminal data)
- Chargebee API (billing/subscription info)
- OpenAI GPT-4o (chat-based answers)

## How to Deploy to Render

1. Fork this repo or upload it to your GitHub account.
2. Go to https://render.com and create a free account.
3. Click "New Web Service", connect to your repo.
4. Set the environment variables:
    - `STARLINK_API_KEY`
    - `CHARGEBEE_API_KEY`
    - `CHARGEBEE_SITE`
    - `OPENAI_API_KEY`
5. Done! Test it with a POST request to `/support` with:

```json
{
  "user_id": "customer_123",
  "message": "How much data have I used?"
}
```

The bot will respond intelligently using your Starlink and Chargebee accounts.
  - type: web
    name: support-bot
    runtime: python
    buildCommand: ""
    startCommand: uvicorn main:app --host 0.0.0.0 --port 10000__pycache__/
.env
    envVars:
      - key: STARLINK_API_KEY
        sync: false
      - key: CHARGEBEE_API_KEY
        sync: false
      - key: CHARGEBEE_SITE
        sync: false
      - key: OPENAI_API_KEY
        sync: false
        reply = await ask_gpt(message)

    return {"reply": reply}
